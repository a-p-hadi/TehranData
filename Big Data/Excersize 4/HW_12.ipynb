{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/15 17:02:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/15 17:02:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/15 17:02:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/03/15 17:02:48 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/03/15 17:02:48 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Hamshahri_1').getOrCreate()\n",
    "\n",
    "text_df_with_filename = spark.read.text(\"./Hamshahri/Hamshahri\").withColumn(\"filename\", substring_index(input_file_name(), \"/\", -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(words, stop_words):\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_2gram_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    cleaned_text = re.sub(r'\\؟', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\،', ' ', cleaned_text)\n",
    "    words = cleaned_text.split()\n",
    "    with open('./Hamshahri/stopwords-fa.txt', 'r', encoding='utf-8') as file:\n",
    "        stopWords = file.read().split(\"\\n\")\n",
    "        stopWords.extend(['text', 'title'])\n",
    "        stopWords.extend(['كه', 'يا', 'اين', 'مي', 'شود'])\n",
    "        words = remove_stop_words(words, stopWords)\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - 3):\n",
    "        ngram = words[i] + \" \" + words[i + 1] + \" \" + words[i + 2] + \" \" + words[i + 3]\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_2gram_text_udf = udf(tokenize_2gram_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = text_df_with_filename.withColumn(\"word\", explode(tokenize_2gram_text_udf(col(\"value\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|               value|           filename|                word|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|نام نويسي كدام مدرسه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|نويسي كدام مدرسه ...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| كدام مدرسه زياد سخت|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|مدرسه زياد سخت نگ...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| زياد سخت نگيريم صبح|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|سخت نگيريم صبح پن...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|نگيريم صبح پنجشنب...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|صبح پنجشنبه 30 خرداد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|پنجشنبه 30 خرداد ماه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  30 خرداد ماه امسال|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| خرداد ماه امسال يكي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|ماه امسال يكي خيا...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|امسال يكي خيابانه...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|يكي خيابانهاي فرع...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|خيابانهاي فرعي مر...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|فرعي مركزشهر تهرا...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|مركزشهر تهران صده...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|تهران صدها دانش آموز|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|صدها دانش آموز همراه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|دانش آموز همراه و...|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:======================================>                 (13 + 6) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------------------------------------------------------------+\n",
      "|word                    |collect_list(struct(filename, count) AS `Name Repeat Count`)                  |\n",
      "+------------------------+------------------------------------------------------------------------------+\n",
      "|0 درصد دقت بفرماييد     |[{HAM2-750409-018.txt, 1}]                                                    |\n",
      "|0 واحدكاهش 86 2004      |[{HAM2-750407-018.txt, 1}]                                                    |\n",
      "|000 180 ليتر نفت        |[{HAM2-750409-007.txt, 1}]                                                    |\n",
      "|014 127 1 نفر           |[{HAM2-750404-052.txt, 1}]                                                    |\n",
      "|1 بار گرانتر نيويورك    |[{HAM2-750407-024.txt, 1}]                                                    |\n",
      "|1 بچه بار تغذيه         |[{HAM2-750405-083.txt, 1}, {HAM2-750402-063.txt, 1}, {HAM2-750407-051.txt, 1}]|\n",
      "|1 دفتر رئيس منطقه       |[{HAM2-750405-054.txt, 1}]                                                    |\n",
      "|1 عقبنشيني اسرائيل اراضي|[{HAM2-750404-071.txt, 1}]                                                    |\n",
      "|1 نفت بهران 12208       |[{HAM2-750407-018.txt, 1}]                                                    |\n",
      "|1 پياده رو خيابان       |[{HAM2-750404-046.txt, 1}]                                                    |\n",
      "|10 10 سريال مردقانون    |[{HAM2-750402-073.txt, 1}, {HAM2-750409-069.txt, 1}]                          |\n",
      "|10 11 امتياز دست        |[{HAM2-750404-103.txt, 1}]                                                    |\n",
      "|10 12 ميليون دلار       |[{HAM2-750407-003.txt, 1}]                                                    |\n",
      "|10 بود سال 1373         |[{HAM2-750407-037.txt, 1}]                                                    |\n",
      "|10 حمام عمومي خورشيدي   |[{HAM2-750409-007.txt, 1}]                                                    |\n",
      "|10 روستاي منطقه محل     |[{HAM2-750407-045.txt, 1}]                                                    |\n",
      "|10 مجيد اكبري دستجردي   |[{HAM2-750403-072.txt, 1}]                                                    |\n",
      "|10 هزار دلار معادل      |[{HAM2-750406-017.txt, 1}]                                                    |\n",
      "|10 هزار نفري مواد       |[{HAM2-750409-007.txt, 1}]                                                    |\n",
      "|10 پرچم هستند درخت      |[{HAM2-750409-080.txt, 1}]                                                    |\n",
      "+------------------------+------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df = tokenized_df.groupBy(\"word\", \"filename\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "grouped_df = result_df.groupBy('word').agg(collect_list(struct('filename', 'count').alias('Name Repeat Count')))\n",
    "\n",
    "grouped_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=========================================>              (14 + 5) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|word                        |count|\n",
      "+----------------------------+-----+\n",
      "|واحد رسانه هاي خارجي        |24   |\n",
      "|گزارش خبرگزاري جمهوري اسلامي|21   |\n",
      "|آيت الله دكتر بهشتي         |16   |\n",
      "|هاشمي رفسنجاني رئيس جمهوري  |14   |\n",
      "|آقاي هاشمي رفسنجاني رئيس    |14   |\n",
      "|گزارش واحد مركزي خبر        |12   |\n",
      "|رسانه هاي خارجي همشهري      |11   |\n",
      "|آثار طبيعي حيات وحش         |10   |\n",
      "|طبيعي حيات وحش ايران        |9    |\n",
      "|موزه آثار طبيعي حيات        |9    |\n",
      "|مرحله يك چهارم نهايي        |9    |\n",
      "|شهيد مظلوم آيت الله         |8    |\n",
      "|فوتبال جام ملتهاي اروپا     |8    |\n",
      "|مقدماتي جام ملتهاي آسيا     |8    |\n",
      "|اداره كل آموزش پرورش        |8    |\n",
      "|كرد گزارش خبرگزاري فرانسه   |8    |\n",
      "|مسابقه هاي فوتبال جام       |8    |\n",
      "|سكه بهار آزادي طرح          |8    |\n",
      "|بوده است پيش بيني           |7    |\n",
      "|ميزان معامله شده قيمت       |7    |\n",
      "+----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result2_df = tokenized_df.groupBy(\"word\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "result2_df.orderBy(result2_df['count'].desc()).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
