{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/15 17:00:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/15 17:00:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/15 17:00:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/03/15 17:00:14 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Hamshahri_1').getOrCreate()\n",
    "\n",
    "text_df_with_filename = spark.read.text(\"./Hamshahri/Hamshahri\").withColumn(\"filename\", substring_index(input_file_name(), \"/\", -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(words, stop_words):\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_2gram_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    cleaned_text = re.sub(r'\\؟', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\،', ' ', cleaned_text)\n",
    "    words = cleaned_text.split()\n",
    "    with open('./Hamshahri/stopwords-fa.txt', 'r', encoding='utf-8') as file:\n",
    "        stopWords = file.read().split(\"\\n\")\n",
    "        stopWords.extend(['text', 'title'])\n",
    "        stopWords.extend(['كه', 'يا', 'اين'])\n",
    "        words = remove_stop_words(words, stopWords)\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - 2):\n",
    "        ngram = words[i] + \" \" + words[i + 1] + \" \" + words[i + 2]\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_2gram_text_udf = udf(tokenize_2gram_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = text_df_with_filename.withColumn(\"word\", explode(tokenize_2gram_text_udf(col(\"value\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|               value|           filename|                word|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      نام نويسي كدام|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    نويسي كدام مدرسه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     كدام مدرسه زياد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      مدرسه زياد سخت|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     زياد سخت نگيريم|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      سخت نگيريم صبح|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  نگيريم صبح پنجشنبه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      صبح پنجشنبه 30|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    پنجشنبه 30 خرداد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|        30 خرداد ماه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     خرداد ماه امسال|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|       ماه امسال يكي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| امسال يكي خيابانهاي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  يكي خيابانهاي فرعي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|خيابانهاي فرعي مر...|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  فرعي مركزشهر تهران|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  مركزشهر تهران صدها|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     تهران صدها دانش|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      صدها دانش آموز|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     دانش آموز همراه|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:============================================>           (15 + 4) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|word                            |collect_list(struct(filename, count) AS `Name Repeat Count`)                                                                      |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0 درصد معادل                    |[{HAM2-750409-018.txt, 1}]                                                                                                        |\n",
      "|000 000 180                     |[{HAM2-750409-007.txt, 1}]                                                                                                        |\n",
      "|000 180 ليتر                    |[{HAM2-750409-007.txt, 1}]                                                                                                        |\n",
      "|048 19855ونزوئلا260 19837اندونزي|[{HAM2-750404-006.txt, 1}]                                                                                                        |\n",
      "|1 بچه هربار                     |[{HAM2-750404-085.txt, 1}]                                                                                                        |\n",
      "|1 تاييد مجدد                    |[{HAM2-750407-073.txt, 1}]                                                                                                        |\n",
      "|1 تهران انباشتگاه               |[{HAM2-750402-044.txt, 1}]                                                                                                        |\n",
      "|1 دلار بالا                     |[{HAM2-750403-013.txt, 1}]                                                                                                        |\n",
      "|1 سرمايه گذاري                  |[{HAM2-750407-018.txt, 2}]                                                                                                        |\n",
      "|1 عقبنشيني اسرائيل              |[{HAM2-750404-071.txt, 1}]                                                                                                        |\n",
      "|1 مبارزه مديريت                 |[{HAM2-750406-042.txt, 1}]                                                                                                        |\n",
      "|1 گرمسار بازرسي                 |[{HAM2-750406-023.txt, 1}]                                                                                                        |\n",
      "|10 10 سريال                     |[{HAM2-750407-065.txt, 1}, {HAM2-750409-069.txt, 1}, {HAM2-750402-073.txt, 1}, {HAM2-750404-077.txt, 1}, {HAM2-750405-080.txt, 1}]|\n",
      "|10 12 ميليون                    |[{HAM2-750407-003.txt, 1}]                                                                                                        |\n",
      "|10 18 خالد                      |[{HAM2-750409-003.txt, 1}]                                                                                                        |\n",
      "|10 امتياز فرهنگي                |[{HAM2-750405-016.txt, 1}]                                                                                                        |\n",
      "|10 حمام عمومي                   |[{HAM2-750409-007.txt, 1}]                                                                                                        |\n",
      "|10 خردسالان 12                  |[{HAM2-750404-077.txt, 1}]                                                                                                        |\n",
      "|10 داروسازي اسوه                |[{HAM2-750403-009.txt, 1}]                                                                                                        |\n",
      "|10 درصد است                     |[{HAM2-750403-014.txt, 1}]                                                                                                        |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df = tokenized_df.groupBy(\"word\", \"filename\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "grouped_df = result_df.groupBy('word').agg(collect_list(struct('filename', 'count').alias('Name Repeat Count')))\n",
    "\n",
    "grouped_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:======================================>                 (13 + 6) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|word                  |count|\n",
      "+----------------------+-----+\n",
      "|برگزار مي شود         |50   |\n",
      "|جمهوري اسلامي ايران   |43   |\n",
      "|خبرگزاري جمهوري اسلامي|41   |\n",
      "|گزارش خبرگزاري فرانسه |41   |\n",
      "|مجلس شوراي اسلامي     |33   |\n",
      "|آقاي هاشمي رفسنجاني   |33   |\n",
      "|جام ملتهاي اروپا      |29   |\n",
      "|رسانه هاي خارجي       |26   |\n",
      "|واحد رسانه هاي        |24   |\n",
      "|تيم ملي فوتبال        |23   |\n",
      "|گزارش روابط عمومي     |23   |\n",
      "|گزارش خبرگزاري جمهوري |21   |\n",
      "|سرويس علمي فرهنگي     |20   |\n",
      "|مي شود سرويس          |20   |\n",
      "|زندگي مي كنند         |19   |\n",
      "|گزارش خبرنگار همشهري  |19   |\n",
      "|كرد گزارش خبرگزاري    |19   |\n",
      "|جام ملتهاي آسيا       |18   |\n",
      "|صورت مي گيرد          |18   |\n",
      "|شهداي هفتم تير        |18   |\n",
      "+----------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result2_df = tokenized_df.groupBy(\"word\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "result2_df.orderBy(result2_df['count'].desc()).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
