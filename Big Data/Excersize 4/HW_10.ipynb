{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/15 16:53:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/15 16:53:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/15 16:53:12 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Hamshahri_1').getOrCreate()\n",
    "\n",
    "text_df_with_filename = spark.read.text(\"./Hamshahri/Hamshahri\").withColumn(\"filename\", substring_index(input_file_name(), \"/\", -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(words, stop_words):\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(words):\n",
    "    return [word.strip() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize_2gram_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    cleaned_text = re.sub(r'\\؟', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\،', ' ', cleaned_text)\n",
    "    words = cleaned_text.split()\n",
    "    df = pd.DataFrame(words, columns=['word'])\n",
    "    # print(len(words))\n",
    "    with open('./Hamshahri/stopwords-fa.txt', 'r', encoding='utf-8') as file:\n",
    "        stopWords = file.read().split(\"\\n\")\n",
    "        stopWords = clean_words(stopWords)\n",
    "        stopWords.extend(['text', 'title'])\n",
    "        stopWords.extend(['كه', 'يا', 'اين'])\n",
    "        words = remove_stop_words(words, stopWords)\n",
    "        df['new_words'] = df['word'].apply(lambda x: None if x in stopWords else x)\n",
    "    # if 'title' in words:\n",
    "    #     words.remove('title')\n",
    "    # if 'text' in words:\n",
    "    #     words.remove('text')\n",
    "    df.to_csv(\"output_text_file.txt\", sep=' ')\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        ngram = words[i] + \" \" + words[i + 1]\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello from isfahan Entekhab\"\n",
    "a = tokenize_2gram_text(text)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_2gram_text_udf = udf(tokenize_2gram_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "specific_item = text_df_with_filename.filter(col(\"filename\") == 'HAM2-750403-045.txt').select(col(\"value\")).first()\n",
    "\n",
    "if specific_item is not None:\n",
    "    text_of_specific_item = specific_item['value']\n",
    "    a = tokenize_2gram_text(text_of_specific_item)\n",
    "    # print('Token: ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = text_df_with_filename.withColumn(\"word\", explode(tokenize_2gram_text_udf(col(\"value\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------+\n",
      "|               value|           filename|          word|\n",
      "+--------------------+-------------------+--------------+\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     نام نويسي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    نويسي كدام|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    كدام مدرسه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    مدرسه زياد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      زياد سخت|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    سخت نگيريم|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    نگيريم صبح|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|   صبح پنجشنبه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    پنجشنبه 30|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      30 خرداد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     خرداد ماه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     ماه امسال|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     امسال يكي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| يكي خيابانهاي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|خيابانهاي فرعي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  فرعي مركزشهر|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt| مركزشهر تهران|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    تهران صدها|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     صدها دانش|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     دانش آموز|\n",
      "+--------------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------------------------------------------------------------+\n",
      "|word            |collect_list(struct(filename, count) AS `Name Repeat Count`)                  |\n",
      "+----------------+------------------------------------------------------------------------------+\n",
      "|0 ميانه         |[{HAM2-750407-038.txt, 1}]                                                    |\n",
      "|072 1987288آلمان|[{HAM2-750404-006.txt, 1}]                                                    |\n",
      "|1 3             |[{HAM2-750405-016.txt, 1}]                                                    |\n",
      "|1 6             |[{HAM2-750403-014.txt, 1}]                                                    |\n",
      "|1 بار           |[{HAM2-750407-024.txt, 1}]                                                    |\n",
      "|1 بامداد        |[{HAM2-750405-042.txt, 1}]                                                    |\n",
      "|1 توسعه         |[{HAM2-750403-009.txt, 1}]                                                    |\n",
      "|1 دلاربراي      |[{HAM2-750405-002.txt, 1}]                                                    |\n",
      "|1 سرمايه        |[{HAM2-750407-018.txt, 2}]                                                    |\n",
      "|1 كرج           |[{HAM2-750406-044.txt, 1}]                                                    |\n",
      "|1 ليفت          |[{HAM2-750403-009.txt, 1}]                                                    |\n",
      "|1 متر           |[{HAM2-750405-083.txt, 1}, {HAM2-750405-088.txt, 1}]                          |\n",
      "|1 هدفتان        |[{HAM2-750404-005.txt, 1}]                                                    |\n",
      "|1 پايان         |[{HAM2-750404-045.txt, 1}]                                                    |\n",
      "|10 11           |[{HAM2-750407-073.txt, 1}, {HAM2-750404-103.txt, 1}]                          |\n",
      "|10 20           |[{HAM2-750405-016.txt, 1}]                                                    |\n",
      "|10 ارتش         |[{HAM2-750406-057.txt, 1}]                                                    |\n",
      "|10 خواهد        |[{HAM2-750405-016.txt, 1}]                                                    |\n",
      "|10 درصد         |[{HAM2-750405-009.txt, 1}, {HAM2-750403-014.txt, 1}, {HAM2-750405-016.txt, 1}]|\n",
      "|10 دسامبر       |[{HAM2-750407-020.txt, 1}]                                                    |\n",
      "+----------------+------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df = tokenized_df.groupBy(\"word\", \"filename\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "grouped_df = result_df.groupBy('word').agg(collect_list(struct('filename', 'count').alias('Name Repeat Count')))\n",
    "\n",
    "grouped_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:============================================>           (15 + 4) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          word|count|\n",
      "+--------------+-----+\n",
      "|        مي شود|  460|\n",
      "|       شده است|  324|\n",
      "|        مي كند|  263|\n",
      "|       مي كنند|  166|\n",
      "|      كرده است|  128|\n",
      "|      خواهد شد|  120|\n",
      "| جمهوري اسلامي|  118|\n",
      "|   رئيس جمهوري|  107|\n",
      "|   دانش آموزان|  106|\n",
      "|       مي گويد|   97|\n",
      "|        مي دهد|   91|\n",
      "|    بين المللي|   88|\n",
      "|خبرنگار همشهري|   87|\n",
      "|     مي توانند|   81|\n",
      "|      بوده است|   81|\n",
      "| شهرداري تهران|   81|\n",
      "|      هفتم تير|   77|\n",
      "|       مي توان|   77|\n",
      "|       مي شوند|   75|\n",
      "|گزارش خبرگزاري|   75|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result2_df = tokenized_df.groupBy(\"word\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "result2_df.orderBy(result2_df['count'].desc()).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
