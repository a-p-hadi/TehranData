{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/15 15:33:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Hamshahri_1').getOrCreate()\n",
    "\n",
    "text_df_with_filename = spark.read.text(\"./Hamshahri/Hamshahri\").withColumn(\"filename\", substring_index(input_file_name(), \"/\", -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_2gram_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    cleaned_text = re.sub(r'\\؟', ' ', cleaned_text)\n",
    "    words = cleaned_text.split()\n",
    "    if 'title' in words:\n",
    "        words.remove('title')\n",
    "    if 'text' in words:\n",
    "        words.remove('text')\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        ngram = words[i] + \" \" + words[i + 1]\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_2gram_text_udf = udf(tokenize_2gram_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = text_df_with_filename.withColumn(\"word\", explode(tokenize_2gram_text_udf(col(\"value\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------+\n",
      "|               value|           filename|          word|\n",
      "+--------------------+-------------------+--------------+\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     نام نويسي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      نويسي در|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|       در كدام|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    كدام مدرسه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    مدرسه زياد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      زياد سخت|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    سخت نگيريم|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    نگيريم صبح|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|       صبح روز|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|   روز پنجشنبه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|    پنجشنبه 30|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      30 خرداد|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     خرداد ماه|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|     ماه امسال|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|      امسال در|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|        در يكي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|        يكي از|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  از خيابانهاي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|خيابانهاي فرعي|\n",
      "|{\"title\":\"نام نوي...|HAM2-750405-016.txt|  فرعي مركزشهر|\n",
      "+--------------------+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=========================================>              (14 + 5) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------------------------------------------+\n",
      "|word            |collect_list(struct(filename, count) AS `Name Repeat Count`)|\n",
      "+----------------+------------------------------------------------------------+\n",
      "|0 ميانه         |[{HAM2-750407-038.txt, 1}]                                  |\n",
      "|072 1987288آلمان|[{HAM2-750404-006.txt, 1}]                                  |\n",
      "|1 6             |[{HAM2-750403-014.txt, 1}]                                  |\n",
      "|1 بار           |[{HAM2-750407-024.txt, 1}]                                  |\n",
      "|1 توسعه         |[{HAM2-750403-009.txt, 1}]                                  |\n",
      "|1 دلاربراي      |[{HAM2-750405-002.txt, 1}]                                  |\n",
      "|1 سرمايه        |[{HAM2-750407-018.txt, 2}]                                  |\n",
      "|1 كرج           |[{HAM2-750406-044.txt, 1}]                                  |\n",
      "|1 ليفت          |[{HAM2-750403-009.txt, 1}]                                  |\n",
      "|1 متر           |[{HAM2-750405-083.txt, 1}, {HAM2-750405-088.txt, 1}]        |\n",
      "|1 هدفتان        |[{HAM2-750404-005.txt, 1}]                                  |\n",
      "|10 خردسال،      |[{HAM2-750406-057.txt, 1}]                                  |\n",
      "|10 خواهد        |[{HAM2-750405-016.txt, 1}]                                  |\n",
      "|10 سرنشين       |[{HAM2-750403-035.txt, 1}]                                  |\n",
      "|10 شرط          |[{HAM2-750403-003.txt, 1}]                                  |\n",
      "|10 كيلومتري     |[{HAM2-750407-034.txt, 1}]                                  |\n",
      "|10 مجيد         |[{HAM2-750403-072.txt, 1}]                                  |\n",
      "|10 و13          |[{HAM2-750405-016.txt, 1}]                                  |\n",
      "|10 واحد         |[{HAM2-750405-057.txt, 1}]                                  |\n",
      "|100 6050        |[{HAM2-750407-018.txt, 1}]                                  |\n",
      "+----------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df = tokenized_df.groupBy(\"word\", \"filename\").agg(\n",
    "    count(\"word\").cast('int').alias(\"count\")\n",
    ")\n",
    "\n",
    "grouped_df = result_df.groupBy('word').agg(collect_list(struct('filename', 'count').alias('Name Repeat Count')))\n",
    "\n",
    "grouped_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
